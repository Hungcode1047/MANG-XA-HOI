{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iT0oBU70HFF"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "class GraphLinkPredictor:\n",
        "    def __init__(self, dataset='karate'):\n",
        "        \"\"\"\n",
        "        Initialize the predictor with a specific dataset.\n",
        "\n",
        "        Parameters:\n",
        "            dataset (str): Name of the dataset ('karate' or 'les').\n",
        "        \"\"\"\n",
        "        available_datasets = {'karate': nx.karate_club_graph, 'les': nx.les_miserables_graph}\n",
        "        if dataset in available_datasets:\n",
        "            self.graph = available_datasets[dataset]()\n",
        "        else:\n",
        "            raise ValueError(\"Only 'karate' and 'les' datasets are supported.\")\n",
        "\n",
        "    def analyze_graph(self):\n",
        "        \"\"\"Basic analysis of the graph.\"\"\"\n",
        "        print(\"\\n=== Graph Analysis ===\")\n",
        "        print(f\"Number of nodes: {self.graph.number_of_nodes()}\")\n",
        "        print(f\"Number of edges: {self.graph.number_of_edges()}\")\n",
        "        print(f\"Average clustering coefficient: {nx.average_clustering(self.graph):.3f}\")\n",
        "\n",
        "        pos = nx.spring_layout(self.graph, seed=42)\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Draw the graph structure\n",
        "        plt.subplot(121)\n",
        "        nx.draw(self.graph, pos, with_labels=True, node_color='skyblue', node_size=600, font_size=9)\n",
        "        plt.title(\"Graph Structure\")\n",
        "\n",
        "        # Degree distribution\n",
        "        plt.subplot(122)\n",
        "        degrees = [deg for _, deg in self.graph.degree()]\n",
        "        sns.histplot(degrees, bins=10, color=\"lightblue\", edgecolor=\"black\")\n",
        "        plt.title(\"Degree Distribution\")\n",
        "        plt.xlabel(\"Degree\")\n",
        "        plt.ylabel(\"Frequency\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def prepare_training_data(self):\n",
        "        \"\"\"Prepare training and testing datasets based on graph edges.\"\"\"\n",
        "        print(\"\\n=== Preparing Data ===\")\n",
        "        all_edges = list(self.graph.edges())\n",
        "        train_edges, test_edges = train_test_split(all_edges, test_size=0.2, random_state=42)\n",
        "\n",
        "        self.training_graph = self.graph.copy()\n",
        "        self.training_graph.remove_edges_from(test_edges)\n",
        "\n",
        "        non_edges = list(nx.non_edges(self.training_graph))\n",
        "        np.random.shuffle(non_edges)\n",
        "        test_non_edges = non_edges[:len(test_edges)]\n",
        "\n",
        "        self.train_edges = train_edges\n",
        "        self.test_edges = test_edges\n",
        "        self.test_non_edges = test_non_edges\n",
        "\n",
        "        print(f\"Training edges: {len(train_edges)}\")\n",
        "        print(f\"Testing edges: {len(test_edges)}\")\n",
        "\n",
        "    def calculate_score(self, u, v, method='common_neighbors'):\n",
        "        \"\"\"Calculate the score for a given node pair based on the selected method.\"\"\"\n",
        "        if method == 'common_neighbors':\n",
        "            return len(list(nx.common_neighbors(self.training_graph, u, v)))\n",
        "        elif method == 'jaccard':\n",
        "            return next(nx.jaccard_coefficient(self.training_graph, [(u, v)]))[2]\n",
        "        elif method == 'adamic_adar':\n",
        "            return next(nx.adamic_adar_index(self.training_graph, [(u, v)]))[2]\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported method\")\n",
        "\n",
        "    def extract_edge_features(self, edges):\n",
        "        \"\"\"Extract features for a list of edges.\"\"\"\n",
        "        features = []\n",
        "        for u, v in edges:\n",
        "            features.append([\n",
        "                self.calculate_score(u, v, 'common_neighbors'),\n",
        "                self.calculate_score(u, v, 'jaccard'),\n",
        "                self.calculate_score(u, v, 'adamic_adar')\n",
        "            ])\n",
        "        return np.array(features)\n",
        "\n",
        "    def evaluate_predictions(self):\n",
        "        \"\"\"Evaluate the prediction methods on the test set.\"\"\"\n",
        "        print(\"\\n=== Evaluation ===\")\n",
        "\n",
        "        X_test = self.extract_edge_features(self.test_edges + self.test_non_edges)\n",
        "        y_test = np.hstack([np.ones(len(self.test_edges)), np.zeros(len(self.test_non_edges))])\n",
        "\n",
        "        methods = ['Common Neighbors', 'Jaccard', 'Adamic/Adar']\n",
        "        results = []\n",
        "\n",
        "        for i, method in enumerate(methods):\n",
        "            scores = X_test[:, i]\n",
        "            threshold = np.percentile(scores, 70)\n",
        "            predictions = (scores > threshold).astype(int)\n",
        "\n",
        "            acc = accuracy_score(y_test, predictions)\n",
        "            prec = precision_score(y_test, predictions)\n",
        "            rec = recall_score(y_test, predictions)\n",
        "\n",
        "            results.append([method, acc, prec, rec])\n",
        "\n",
        "        df_results = pd.DataFrame(results, columns=['Method', 'Accuracy', 'Precision', 'Recall'])\n",
        "        print(df_results)\n",
        "\n",
        "    def execute(self):\n",
        "        \"\"\"Execute the complete workflow.\"\"\"\n",
        "        self.analyze_graph()\n",
        "        self.prepare_training_data()\n",
        "        self.evaluate_predictions()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Select dataset:\\n1. Karate Club\\n2. Les Miserables\")\n",
        "    user_choice = input(\"Enter your choice (1/2): \")\n",
        "    dataset_mapping = {'1': 'karate', '2': 'les'}\n",
        "\n",
        "    if user_choice in dataset_mapping:\n",
        "        predictor = GraphLinkPredictor(dataset_mapping[user_choice])\n",
        "        predictor.execute()\n",
        "    else:\n",
        "        print(\"Invalid choice!\")\n"
      ]
    }
  ]
}